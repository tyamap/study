import numpy as np

# ====================
# スカラー、ベクトル、行列、テンソル

# 一次元配列でベクトルを表す
a = np.array([1,2,3])
b = np.array([-2.4, 0.25, -1.3, 1.8, 0.61])
print(a)
print(b)

# 二次元配列で行列を表す
a = np.array([[1, 2, 3],
              [4, 5, 6]])
b = np.array([[0.21, 0.14],
              [1.3, 0.81],
              [0.12, -2.1]])
print(a)
print(b)

# 三次元以上の配列で簡易的にテンソルを表す
a = np.array([[[0, 1, 2, 3],
               [2, 3, 4, 5],
               [4, 5, 6, 7]],
              
               [[1, 2, 3, 4],
                [3, 4, 5, 6],
                [5, 6, 7, 8]]])
print(a) # 三階のテンソル

# ====================
# ベクトルの内積とノルム

# ベクトル同士の内積はベクトルの各要素同士の積の総和
# $$\vec{a}.\vec{b}=\sum_{k=1}^n a_kb_k$$

a = np.array([1, 2, 3])
b = np.array([3, 2, 1])
print(np.dot(a,b)) # dot関数による内積
print(np.sum(a * b)) # 積の総和による内積

# ノルムはベクトルの「大きさ」を表す量
# NumPyの linalg.norm 関数を用いて実装する。

# L2ノルム: ベクトルの各要素を二乗和して平方根を取って計算
a = np.array([1, 1, -1, -1])
print("----- L2ノルム -----")
print(np.linalg.norm(a))

# L1ノルム: ベクトルの各要素の絶対値を足し合わせて計算
print("----- L1ノルム -----")
print(np.linalg.norm(a, 1))

# ----- note -----
# ノルムは人工知能において「正則化」に用いられる。
# 正則化とは、必要以上にネットワークの学習が進んでしまうことを、パラメータを調節することにより予防すること